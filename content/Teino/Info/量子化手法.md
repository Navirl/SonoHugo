---
date: 2024-12-21T15:24:24+09:00
title: "量子化手法"
tags:
  - Info
---

daily:: [2023-11-07](/Daily_Note/2023-11-07.md)
up:: [AI_local](../Bar/AI/AI_local.md)

GGML
旧手法。Cで書かれており、サードパーティに依存せず、量子化をサポートする。
あとWebAssemblyサポートとか。

GGUF
Llama以外もllama.cppで使えるようになる新フォーマット。
プロンプトフォーマットを内部に設定しておける。

GPTQ
推論速度の高速化。

ExllamaとかがLlama専用でこの圧縮を行っていたが、AutoGPTQによりTransformerモデル全てで圧縮できるようになった。
量子化した後量子化そのものを学習し、元モデルとの誤差を縮めている。

AWQ
最近出てきたGPTQの上位版量子化。


[GGML/GGUF/GPTQの違い](https://zenn.dev/kun432/scraps/6fc012752afa62)
